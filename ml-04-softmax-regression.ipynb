{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist=fetch_openml('mnist_784', version=1, parser='auto')\n",
    "\n",
    "print(mnist.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all, y_all = mnist['data'].to_numpy(), mnist['target'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all_i = np.ndarray(shape=y_all.shape)\n",
    "for i in range(70000):\n",
    "    y_all_i[i]=int(y_all[i])\n",
    "\n",
    "# Training data\n",
    "X_train=X_all[:1000]\n",
    "y_train=y_all[:1000]\n",
    "\n",
    "# Test data\n",
    "X_test=X_all[1000:]\n",
    "y_test=y_all[1000:]\n",
    "y_test_i=y_all_i[1000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_digit=X_all[-1]\n",
    "some_digit_image=some_digit.reshape(28, 28)\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(some_digit_image, cmap=\"binary\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y):\n",
    "    one_hot_y = np.zeros((y.size, 10))\n",
    "\n",
    "    for i in range(y.size):\n",
    "        j = int(y[i])\n",
    "        one_hot_y[i][j] = 1\n",
    "    return one_hot_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    z = z - z.max()\n",
    "    return np.exp(z) / np.sum(np.exp(z))\n",
    "\n",
    "\n",
    "# softmax for matrices\n",
    "def softmax_m(Z):\n",
    "    sm = np.ndarray(shape=(Z.shape))\n",
    "    for i in range(Z.shape[0]):\n",
    "        sm[i]=softmax(Z[i])\n",
    "    return sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train\n",
    "y = one_hot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch/Full Gradient descent\n",
    "\n",
    "eta = 0.1 #learning rate\n",
    "n_iterations = 500\n",
    "\n",
    "m = 1000\n",
    "\n",
    "W = np.random.rand(784, 10) -0.5\n",
    "b = np.random.rand(1,   10) -0.5\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    \n",
    "    p = softmax_m(X.dot(W) + b)\n",
    "\n",
    "    W_grad = 1/m*X.T.dot(p-y)\n",
    "    b_grad = 1/m*np.sum(p-y)\n",
    "\n",
    "    W-= eta*W_grad\n",
    "    b-= eta*b_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8316811594202899"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = softmax_m(X_test.dot(W) + b)\n",
    "\n",
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "\n",
    "# Accuracy\n",
    "np.sum(y_pred==y_test_i)/y_test_i.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12545988,  0.45071431,  0.23199394, ...,  0.36617615,\n",
       "         0.10111501,  0.20807258],\n",
       "       [-0.47941551,  0.46990985,  0.33244264, ...,  0.02475643,\n",
       "        -0.06805498, -0.20877086],\n",
       "       [ 0.11185289, -0.36050614, -0.20785535, ...,  0.01423444,\n",
       "         0.09241457, -0.45354959],\n",
       "       ...,\n",
       "       [-0.27690998, -0.44348431, -0.39660506, ...,  0.4405373 ,\n",
       "         0.40594397,  0.06680611],\n",
       "       [-0.14557601, -0.11885312, -0.08814772, ..., -0.16405385,\n",
       "         0.06069448, -0.40494346],\n",
       "       [-0.29953095, -0.08653423, -0.29379728, ...,  0.19186391,\n",
       "        -0.11693063,  0.36909907]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1000, multi_class=&#x27;multinomial&#x27;, solver=&#x27;newton-cg&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1000, multi_class=&#x27;multinomial&#x27;, solver=&#x27;newton-cg&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1000, multi_class='multinomial', solver='newton-cg')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Softmax using library\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "softmax_reg = LogisticRegression(multi_class=\"multinomial\", solver=\"newton-cg\", C=1000)\n",
    "softmax_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8403333333333334"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(softmax_reg.predict(X_test)==y_test)/y_test.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lbfgs relatively performs well compared to other methods and it saves a lot of memory, however, sometimes it may have issues with convergence.\n",
    "\n",
    "sag faster than other solvers for large datasets, when both the number of samples and the number of features are large.\n",
    "\n",
    "saga the solver of choice for sparse multinomial logistic regression and it’s also suitable for very large datasets.\n",
    "\n",
    "newton-cg computationally expensive because of the Hessian Matrix.\n",
    "\n",
    "liblinearrecommended when you have a high dimension dataset - solving large-scale classification problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
